{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "cellView": "both",
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "xHEUntSwppKT"
   },
   "outputs": [],
   "source": [
    "#@title\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow import feature_column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "Fk8EvBEGrV-5",
    "outputId": "d8fadfbb-4876-43bd-e259-daf0f8486b4b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fatal: destination path 'python-binder' already exists and is not an empty directory.\n"
     ]
    }
   ],
   "source": [
    "!git clone https://github.com/jyluo1994/python-binder.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 134
    },
    "colab_type": "code",
    "id": "ufdX9nu4ppKY",
    "outputId": "977775f4-0e2a-495e-f474-41d6a90c6b02"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['death', 'recurrence', 'metastasis', 'progression', 'age', 'gender',\n",
       "       'treatment', 'IC.N', 'CC.N', 'AC.N', 'pathology', 'T', 'N',\n",
       "       'UICC.Stage', 'smoking', 'family.history', 'EBVDNA', 'BMI', 'WBC',\n",
       "       'NEU', 'LYM', 'MON', 'HGB', 'PLT', 'LDH', 'ALB', 'TBIL', 'DBIL', 'IBIL',\n",
       "       'BUN', 'CRE', 'UA', 'CHO', 'TG', 'HDL.C', 'LDL.C', 'ApoA1', 'ApoB',\n",
       "       'CRP', 'VCA.IgA', 'EA.IgA'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 103,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('python-binder/7y_nona.csv')\n",
    "df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "pJ-CN4W4ppKe"
   },
   "source": [
    "然后我们来分割数据。这里使用的是 Scikit-learn 中的 train_test_split 函数。指定分割比例即可。\n",
    "我们先按照 80:20 的比例，把总体数据分成训练集和测试集。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "W0m0TQBappKf"
   },
   "outputs": [],
   "source": [
    "tf.random.set_seed(1)\n",
    "train, test = train_test_split(df, test_size=0.2, random_state=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "AzwrVcY_ppKi"
   },
   "source": [
    "然后，再把现有训练集的数据，按照 80:20 的比例，分成最终的训练集，以及验证集。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "j5gQkpyGppKj"
   },
   "outputs": [],
   "source": [
    "train,valid = train_test_split(train, test_size=0.25, random_state=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "dPyrz5YZppKm"
   },
   "source": [
    "这里，我们都指定了 random_state ，为的是保证咱们随机分割的结果一致。\n",
    "我们看看几个不同集合的长度。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 67
    },
    "colab_type": "code",
    "id": "7H_y4VB7ppKm",
    "outputId": "bbd9e13c-8e36-4d52-f912-c0841bc58cef"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "486\n",
      "162\n",
      "163\n"
     ]
    }
   ],
   "source": [
    "print(len(train))\n",
    "print(len(valid))\n",
    "print(len(test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 638
    },
    "colab_type": "code",
    "id": "Z8e_K24yppKq",
    "outputId": "dfe0d368-2e3a-438e-e8db-980a83ca2b19"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[NumericColumn(key='age', shape=(1,), default_value=None, dtype=tf.float32, normalizer_fn=<function <lambda> at 0x7f5c98a2c9d8>),\n",
       " NumericColumn(key='EBVDNA', shape=(1,), default_value=None, dtype=tf.float32, normalizer_fn=<function <lambda> at 0x7f5c98a2cae8>),\n",
       " NumericColumn(key='BMI', shape=(1,), default_value=None, dtype=tf.float32, normalizer_fn=<function <lambda> at 0x7f5c98a2cb70>),\n",
       " NumericColumn(key='WBC', shape=(1,), default_value=None, dtype=tf.float32, normalizer_fn=<function <lambda> at 0x7f5c98a2cbf8>),\n",
       " NumericColumn(key='NEU', shape=(1,), default_value=None, dtype=tf.float32, normalizer_fn=<function <lambda> at 0x7f5c98a2cc80>),\n",
       " NumericColumn(key='LYM', shape=(1,), default_value=None, dtype=tf.float32, normalizer_fn=<function <lambda> at 0x7f5c98a2cd08>),\n",
       " NumericColumn(key='MON', shape=(1,), default_value=None, dtype=tf.float32, normalizer_fn=<function <lambda> at 0x7f5c98a2cd90>),\n",
       " NumericColumn(key='HGB', shape=(1,), default_value=None, dtype=tf.float32, normalizer_fn=<function <lambda> at 0x7f5c98a2ce18>),\n",
       " NumericColumn(key='PLT', shape=(1,), default_value=None, dtype=tf.float32, normalizer_fn=<function <lambda> at 0x7f5c98a2cea0>),\n",
       " NumericColumn(key='LDH', shape=(1,), default_value=None, dtype=tf.float32, normalizer_fn=<function <lambda> at 0x7f5c98a2cf28>),\n",
       " NumericColumn(key='ALB', shape=(1,), default_value=None, dtype=tf.float32, normalizer_fn=<function <lambda> at 0x7f5c98a1a048>),\n",
       " NumericColumn(key='TBIL', shape=(1,), default_value=None, dtype=tf.float32, normalizer_fn=<function <lambda> at 0x7f5c98a1a0d0>),\n",
       " NumericColumn(key='DBIL', shape=(1,), default_value=None, dtype=tf.float32, normalizer_fn=<function <lambda> at 0x7f5c98a1a158>),\n",
       " NumericColumn(key='IBIL', shape=(1,), default_value=None, dtype=tf.float32, normalizer_fn=<function <lambda> at 0x7f5c98a1a1e0>),\n",
       " NumericColumn(key='BUN', shape=(1,), default_value=None, dtype=tf.float32, normalizer_fn=<function <lambda> at 0x7f5c98a1a268>),\n",
       " NumericColumn(key='CRE', shape=(1,), default_value=None, dtype=tf.float32, normalizer_fn=<function <lambda> at 0x7f5c98a1a2f0>),\n",
       " NumericColumn(key='UA', shape=(1,), default_value=None, dtype=tf.float32, normalizer_fn=<function <lambda> at 0x7f5c98a1a378>),\n",
       " NumericColumn(key='CHO', shape=(1,), default_value=None, dtype=tf.float32, normalizer_fn=<function <lambda> at 0x7f5c98a1a400>),\n",
       " NumericColumn(key='TG', shape=(1,), default_value=None, dtype=tf.float32, normalizer_fn=<function <lambda> at 0x7f5c98a1a488>),\n",
       " NumericColumn(key='HDL.C', shape=(1,), default_value=None, dtype=tf.float32, normalizer_fn=<function <lambda> at 0x7f5c98a1a510>),\n",
       " NumericColumn(key='LDL.C', shape=(1,), default_value=None, dtype=tf.float32, normalizer_fn=<function <lambda> at 0x7f5c98a1a598>),\n",
       " NumericColumn(key='ApoA1', shape=(1,), default_value=None, dtype=tf.float32, normalizer_fn=<function <lambda> at 0x7f5c98a1a620>),\n",
       " NumericColumn(key='ApoB', shape=(1,), default_value=None, dtype=tf.float32, normalizer_fn=<function <lambda> at 0x7f5c98a1a6a8>),\n",
       " NumericColumn(key='CRP', shape=(1,), default_value=None, dtype=tf.float32, normalizer_fn=<function <lambda> at 0x7f5c98a1a730>),\n",
       " NumericColumn(key='VCA.IgA', shape=(1,), default_value=None, dtype=tf.float32, normalizer_fn=<function <lambda> at 0x7f5c98a1a7b8>),\n",
       " NumericColumn(key='EA.IgA', shape=(1,), default_value=None, dtype=tf.float32, normalizer_fn=<function <lambda> at 0x7f5c98a1a840>),\n",
       " IndicatorColumn(categorical_column=VocabularyListCategoricalColumn(key='gender', vocabulary_list=(1, 2), dtype=tf.int64, default_value=-1, num_oov_buckets=0)),\n",
       " IndicatorColumn(categorical_column=VocabularyListCategoricalColumn(key='treatment', vocabulary_list=(4, 1, 2, 5, 6), dtype=tf.int64, default_value=-1, num_oov_buckets=0)),\n",
       " IndicatorColumn(categorical_column=VocabularyListCategoricalColumn(key='IC.N', vocabulary_list=(3, 0, 2, 4, 1, 5), dtype=tf.int64, default_value=-1, num_oov_buckets=0)),\n",
       " IndicatorColumn(categorical_column=VocabularyListCategoricalColumn(key='CC.N', vocabulary_list=(2, 0, 6, 3, 4, 5, 1, 7, 8), dtype=tf.int64, default_value=-1, num_oov_buckets=0)),\n",
       " IndicatorColumn(categorical_column=VocabularyListCategoricalColumn(key='AC.N', vocabulary_list=(0, 3, 2, 1, 4, 5), dtype=tf.int64, default_value=-1, num_oov_buckets=0)),\n",
       " IndicatorColumn(categorical_column=VocabularyListCategoricalColumn(key='pathology', vocabulary_list=(3, 2), dtype=tf.int64, default_value=-1, num_oov_buckets=0)),\n",
       " IndicatorColumn(categorical_column=VocabularyListCategoricalColumn(key='T', vocabulary_list=(2, 4, 3, 1), dtype=tf.int64, default_value=-1, num_oov_buckets=0)),\n",
       " IndicatorColumn(categorical_column=VocabularyListCategoricalColumn(key='N', vocabulary_list=(3, 0, 2, 1), dtype=tf.int64, default_value=-1, num_oov_buckets=0)),\n",
       " IndicatorColumn(categorical_column=VocabularyListCategoricalColumn(key='UICC.Stage', vocabulary_list=(4, 2, 3, 1), dtype=tf.int64, default_value=-1, num_oov_buckets=0)),\n",
       " IndicatorColumn(categorical_column=VocabularyListCategoricalColumn(key='smoking', vocabulary_list=(2, 0, 1, 3), dtype=tf.int64, default_value=-1, num_oov_buckets=0)),\n",
       " IndicatorColumn(categorical_column=VocabularyListCategoricalColumn(key='family.history', vocabulary_list=(0, 1), dtype=tf.int64, default_value=-1, num_oov_buckets=0))]"
      ]
     },
     "execution_count": 107,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_columns = []\n",
    "numeric_columns = ['age', 'EBVDNA', 'BMI', 'WBC',\n",
    "       'NEU', 'LYM', 'MON', 'HGB', 'PLT', 'LDH', 'ALB', 'TBIL', 'DBIL', 'IBIL',\n",
    "       'BUN', 'CRE', 'UA', 'CHO', 'TG', 'HDL.C', 'LDL.C', 'ApoA1', 'ApoB',\n",
    "       'CRP', 'VCA.IgA', 'EA.IgA']\n",
    "    \n",
    "for header in numeric_columns:\n",
    "  feature_columns.append(\n",
    "      feature_column.numeric_column(\n",
    "          header, \n",
    "          normalizer_fn=lambda x: (tf.cast(x, dtype=float)-train[header].mean())/train[header].std()))    \n",
    "    \n",
    "    \n",
    "categorical_columns = ['gender',\n",
    "       'treatment', 'IC.N', 'CC.N', 'AC.N', 'pathology', 'T', 'N',\n",
    "       'UICC.Stage', 'smoking', 'family.history',]\n",
    "\n",
    "def get_one_hot_from_categorical(colname):\n",
    "    categorical = feature_column.categorical_column_with_vocabulary_list(colname, train[colname].unique().tolist())\n",
    "    return feature_column.indicator_column(categorical)\n",
    "\n",
    "\n",
    "\n",
    "for col in categorical_columns:\n",
    "    feature_columns.append(get_one_hot_from_categorical(col))\n",
    "\n",
    "feature_columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "KiI9QMa3ppKu",
    "outputId": "eb7f6c19-3846-4edf-de01-80e1109a191d"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.feature_column.feature_column_v2.DenseFeatures at 0x7f5c98bd5d30>"
      ]
     },
     "execution_count": 108,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tensorflow.keras import layers\n",
    "feature_layer = layers.DenseFeatures(feature_columns)\n",
    "feature_layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 202
    },
    "colab_type": "code",
    "id": "YM7fxf_XppKx",
    "outputId": "6a1c0ead-8189-435a-8320-fde82c80745d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "98/98 [==============================] - 4s 46ms/step - loss: 3.3056 - mse: 0.2018\n",
      "Epoch 2/5\n",
      "98/98 [==============================] - 4s 39ms/step - loss: 3.3056 - mse: 0.2018\n",
      "Epoch 3/5\n",
      "98/98 [==============================] - 4s 39ms/step - loss: 3.3056 - mse: 0.2018\n",
      "Epoch 4/5\n",
      "98/98 [==============================] - 4s 39ms/step - loss: 3.3056 - mse: 0.2018\n",
      "Epoch 5/5\n",
      "98/98 [==============================] - 4s 39ms/step - loss: 3.3056 - mse: 0.2018\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f5c96d30a58>"
      ]
     },
     "execution_count": 120,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sklearn.metrics\n",
    "model = keras.Sequential([\n",
    "    feature_layer,\n",
    "    layers.Dense(200, activation='relu'),\n",
    "    layers.Dense(100, activation='relu'),\n",
    "    layers.Dense(1, activation='sigmoid')\n",
    "])\n",
    "\n",
    "model.compile(optimizer='adam',\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "      \n",
    "def df_to_dataset(dataframe, shuffle=True, batch_size=32):\n",
    "    dataframe = dataframe.copy()\n",
    "    labels = dataframe.pop('progression')\n",
    "    ds = tf.data.Dataset.from_tensor_slices((dict(dataframe), labels))\n",
    "    if shuffle:\n",
    "        ds = ds.shuffle(buffer_size=len(dataframe))\n",
    "    ds = ds.batch(batch_size)\n",
    "    return ds      \n",
    "    \n",
    "batch_size = 5\n",
    "train_ds = df_to_dataset(train, batch_size=batch_size)\n",
    "val_ds = df_to_dataset(valid, shuffle=False, batch_size=batch_size)\n",
    "test_ds = df_to_dataset(test, shuffle=False, batch_size=batch_size)\n",
    "\n",
    "model.fit(train_ds,\n",
    "          validation_data=valid_ds,\n",
    "          epochs=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "VS4hZhH5ppKz",
    "outputId": "c649246f-1c61-4830-ae48-d25807ecb9ca"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.], dtype=float32)"
      ]
     },
     "execution_count": 121,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred = model.predict(test_ds)\n",
    "pred = np.rint(pred)\n",
    "np.unique(pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 202
    },
    "colab_type": "code",
    "id": "eyrFfh50D9VN",
    "outputId": "6c22a625-6225-4442-8efa-d205b6a1223e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      1.00      0.89       130\n",
      "           1       0.00      0.00      0.00        33\n",
      "\n",
      "   micro avg       0.80      0.80      0.80       163\n",
      "   macro avg       0.40      0.50      0.44       163\n",
      "weighted avg       0.64      0.80      0.71       163\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "print(classification_report(test['progression'], pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 50
    },
    "colab_type": "code",
    "id": "psl5Wb6cEJ9a",
    "outputId": "f8c87439-acd3-48d8-d900-eb68cb9bac26"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[130   0]\n",
      " [ 33   0]]\n"
     ]
    }
   ],
   "source": [
    "print(confusion_matrix(test['progression'], pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "lz7pB9Y0VI2T"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 232
    },
    "colab_type": "code",
    "id": "-IC9IvLJRFk0",
    "outputId": "e096ec98-ea3d-4735-b55e-3c639f3319f9"
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "ignored",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-122-450a1f47f9e8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpyplot\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mhistory_dict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhistory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mhistory_dict\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0macc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhistory_dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'accuracy'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mval_acc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhistory_dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'val_accuracy'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'history' is not defined"
     ]
    }
   ],
   "source": [
    "x_val = train.\n",
    "x_train = train_x[10000:]\n",
    "\n",
    "y_val = train_y[:10000]\n",
    "y_train = train_y[10000:]\n",
    "\n",
    "history = model.fit(x_train,y_train,\n",
    "                   epochs=40, batch_size=5,\n",
    "                   validation_data=(x_val, y_val),\n",
    "                   verbose=1)\n",
    "\n",
    "result = model.evaluate(test_x, text_y)\n",
    "print(result)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "Rz8gJdonRZ8Y"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "history_dict = history.history\n",
    "history_dict.keys()\n",
    "acc = history_dict['accuracy']\n",
    "val_acc = history_dict['val_accuracy']\n",
    "loss = history_dict['loss']\n",
    "val_loss = history_dict['val_loss']\n",
    "epochs = range(1, len(acc)+1)\n",
    "\n",
    "plt.plot(epochs, loss, 'bo', label='train loss')\n",
    "plt.plot(epochs, val_loss, 'b', label='val loss')\n",
    "plt.title('Train and val loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.xlabel('loss')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "神经网络-tf2.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
